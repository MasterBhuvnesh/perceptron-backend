[
  {
    "id": "1",
    "title": "EDA",
    "description": "EDA is the initial step in data analysis, using visual and statistical methods to explore data, identify patterns, and spot anomalies before modeling.",
    "theory": [
      "The theoretical foundation of EDA was formally established by statistician John Tukey in the 1970s, who emphasized the importance of using graphical techniques to understand data beyond formal hypothesis testing.",
      "EDA is built on several key principles: a focus on visual representation to see patterns that summary statistics might miss; resistance, which prioritizes methods that are not overly influenced by outliers; and transparency, ensuring the data's story is clear.",
      "It involves two main types of analysis: univariate analysis, which examines the distribution, central tendency, and spread of a single variable (using tools like histograms, box plots, and summary statistics), and multivariate analysis, which explores the relationships and interactions between two or more variables (using scatter plots, correlation matrices, and pair plots).",
      "The ultimate goal is to uncover the underlying structure of the data, identify important variables, detect outliers and anomalies, test underlying assumptions for future modeling, and inform the selection of appropriate analytical techniques."
    ],
    "image": "https://i.pinimg.com/1200x/dd/34/f2/dd34f2caf11d4e4f235559eba14bf832.jpg",
    "summary": "The initial process of analyzing data sets to summarize their main characteristics and uncover underlying patterns, often using visual methods."
  },
  {
    "id": "2",
    "title": "Linear Regression",
    "description": "Linear Regression models the relationship between a continuous target and one or more predictors using a linear equation. It's widely used for both prediction and understanding variable relationships.",
    "theory": [
      "Linear Regression is a fundamental statistical and machine learning technique used to model the relationship between a dependent variable (target) and one or more independent variables (predictors). The simplest form, simple linear regression, models the relationship between two variables using the equation y = β₀ + β₁x + ε, where β₀ is the intercept, β₁ is the slope, and ε is the error term. Multiple linear regression extends this to multiple predictors: y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ + ε.",
      "The primary goal is to estimate the coefficients (β) that minimize the sum of squared residuals (differences between observed and predicted values), a method known as Ordinary Least Squares (OLS). Key assumptions underpinning linear regression include linearity (the relationship between predictors and target is linear), independence (observations are independent), homoscedasticity (constant variance of errors), and normality of errors. Violation of these assumptions can lead to biased or inefficient estimates.",
      "The model's fit is commonly assessed using metrics like R-squared, which measures the proportion of variance explained, and Mean Squared Error (MSE). Statistical tests such as t-tests and F-tests are used to evaluate the significance of individual predictors and the overall model. Regularization techniques like Ridge and Lasso regression can be applied to address multicollinearity and overfitting by penalizing large coefficients.",
      "Linear regression is widely used for prediction, trend analysis, and inferential statistics, providing interpretable insights into the influence of predictors. However, it is sensitive to outliers and may not capture complex, non-linear relationships. Diagnostic plots (residual plots, Q-Q plots) and techniques (cross-validation) are essential for validating model assumptions and performance.",
      "Extensions such as polynomial regression and interaction terms allow modeling of more complex relationships. In practice, feature selection, scaling, and transformation are important preprocessing steps. Linear regression remains a cornerstone of statistical modeling due to its simplicity, interpretability, and effectiveness in many real-world applications, from economics and biology to engineering and social sciences."
    ],
    "image": "https://i.pinimg.com/1200x/dd/34/f2/dd34f2caf11d4e4f235559eba14bf832.jpg",
    "summary": "A foundational statistical method for modeling the linear relationship between a dependent variable and one or more independent variables."
  },
  {
    "id": "3",
    "title": "Classification",
    "description": "Classification is a supervised learning task where models assign inputs to discrete categories or classes, such as spam detection or image recognition.",
    "theory": [
      "The theory of classification revolves around the concept of learning a decision boundary that partitions the feature space into regions, each associated with a specific class. Different algorithms approach this problem in distinct ways. Logistic Regression, despite its name, is a linear classification algorithm that models the probability that a given input belongs to a particular class using the logistic function (sigmoid). It's foundational for understanding how linear models can be adapted for classification.",
      "Decision Trees take a hierarchical, tree-like approach, splitting the data based on feature values to create pure subsets. Ensemble methods like Random Forest combine the predictions of multiple decorrelated decision trees to improve accuracy and robustness, reducing the risk of overfitting.",
      "Support Vector Machines (SVMs) aim to find the optimal hyperplane that maximizes the margin between classes in a high-dimensional space. Neural Networks, particularly deep learning models, use interconnected layers of nodes to learn highly complex, non-linear decision boundaries.",
      "The performance of a classifier is rigorously evaluated using a confusion matrix and derived metrics such as accuracy, precision, recall, and the F1-score, which provide a nuanced view of its strengths and weaknesses across different classes."
    ],
    "image": "https://i.pinimg.com/1200x/dd/34/f2/dd34f2caf11d4e4f235559eba14bf832.jpg",
    "summary": "A predictive modeling task where observations are categorized into discrete classes based on learned patterns from labeled data."
  }
]
